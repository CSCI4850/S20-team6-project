{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains the demo for all aspects of Steganography GAN\n",
    "\n",
    "Our goal is to crack the Least Significant Bit Stenganograpy algorithm using Cycle generative Adversarial Networks. Specifically, we want to train our models the understand how to translate between an encoded image and a decoded image. On top of this, we implement different techniques to show the success of our model and how to improve it. \n",
    "\n",
    "Before running the cells in this notebook, make sure to have gone through the README.md. Specifically, make sure to:\n",
    "\n",
    "1. Have the dataset properly downloaded\n",
    "2. (Optionally - Our repository contains all the images needed to test for bit-size 7) Pre-process the dataset to create all necessary images\n",
    "3. (Optionally) Download the pre-trained weights\n",
    "\n",
    "The cells below will walk through CycleGANs, Autoencoders, Bayesian Optimization, Saved Weights, and Bit Size Training. \n",
    "\n",
    "(We will run the cells that show the results using our pre-trained weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all nessesary packages for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from sten import Sten\n",
    "from matplotlib.image import imread\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call(['./get_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call(['./get_checkpoints_mini'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_mini.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable GPU capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to show the progress of our models as they train\n",
    "\n",
    "This section can be easily replaced with some other tool such as tqdm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(max_epoch, epoch, progress, episode):\n",
    "    bar_length = 50\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Episode {0}, Progress: [{1}] {2:.1f}%, Epoch {3}/{4}\".format(episode, \"=\" * block + \".\" * (bar_length - block), progress * 100, epoch, max_epoch)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CycleGAN: The following code shows how to run the CycleGAN code from scratch or with the use of saved weights and also how to use the Bit Size Training technique\n",
    "\n",
    "The following section contains the main results of our research. In particular, this section will show how to implement Cycle Generative Adversarial Networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the main hyper-parameters that can be altered for this model. The STEN_X specifies to the model which bit size to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH = 50\n",
    "LAMBDA = 10\n",
    "SAVE_RATE = 10\n",
    "STEN_X = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generate_images function prints and saves the cover image, hidden image, encoded image, decoded image, the image generated by Generator G (decoded image), and the image generated by generator F (encoded image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator_g, generator_f, cover_imgs, hidden_imgs, encoded_imgs, decoded_imgs, save_name):\n",
    "    fig, axs = plt.subplots(len(cover_imgs), 6, figsize=(25,25))\n",
    "    cols = [\"Cover\", \"Hidden\", \"Encoded\", \"Decoded\", \"Generator G\", \"Generator F\"]\n",
    "    for x in range(len(cover_imgs)):\n",
    "        predicted_g = generator_g.predict(np.asarray([encoded_imgs[x]]))\n",
    "        predicted_f = generator_f.predict(np.asarray([predicted_g[0]]))\n",
    "        display_list = [cover_imgs[x], hidden_imgs[x], encoded_imgs[x], decoded_imgs[x], predicted_g[0], predicted_f[0]]\n",
    "        [axs[x, y].imshow(display_list[y] * 0.5 + 0.5) for y in range(6)]\n",
    "    [ax.set_title(col,fontsize=40) for ax, col in zip(axs[0], cols)]\n",
    "    [axi.set_axis_off() for axi in axs.ravel()]\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator_loss calculates the loss for the discriminator model in the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(a, generated):\n",
    "    a_loss = loss_obj(tf.ones_like(a), a)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = a_loss + generated_loss\n",
    "    return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator_loss calculates the loss for the generator model in the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "    return loss_obj(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calc_cycle_loss calculates the loss for a single cycle with an encoded image through the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cycle_loss(a_image, cycled_image):\n",
    "    loss1 = tf.reduce_mean(tf.abs(a_image - cycled_image))\n",
    "    return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identity_loss calculates the identity loss for an image and the same image passed into the corresponding generator which should not alter the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(a_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(a_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model runs through the train_step for every encoded and decoded image passed into it. This is the function that changes the weights of our model as it progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(a_x, a_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "            \n",
    "        fake_y = generator_g(a_x, training=True)\n",
    "        cycled_x = generator_f(fake_y, training=True)\n",
    "\n",
    "        fake_x = generator_f(a_y, training=True)\n",
    "        cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "        same_x = generator_f(a_x, training=True)\n",
    "        same_y = generator_g(a_y, training=True)\n",
    "\n",
    "        disc_a_x = discriminator_x(a_x, training=True)\n",
    "        disc_a_y = discriminator_y(a_y, training=True)\n",
    "\n",
    "        disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "        disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "        gen_g_loss = generator_loss(disc_fake_y)\n",
    "        gen_f_loss = generator_loss(disc_fake_x)\n",
    "\n",
    "        total_cycle_loss = calc_cycle_loss(a_x, cycled_x) + calc_cycle_loss(a_y, cycled_y)\n",
    "\n",
    "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(a_y, same_y)\n",
    "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(a_x, same_x)\n",
    "\n",
    "        disc_x_loss = discriminator_loss(disc_a_x, disc_fake_x)\n",
    "        disc_y_loss = discriminator_loss(disc_a_y, disc_fake_y)\n",
    "  \n",
    "    generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
    "                                        generator_g.trainable_variables)\n",
    "    generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
    "                                        generator_f.trainable_variables)\n",
    "\n",
    "    discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                            discriminator_x.trainable_variables)\n",
    "    discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
    "                                            discriminator_y.trainable_variables)\n",
    "\n",
    "    generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            generator_g.trainable_variables))\n",
    "\n",
    "    generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            generator_f.trainable_variables))\n",
    "\n",
    "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                discriminator_x.trainable_variables))\n",
    "\n",
    "    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the generator models, discriminator models, and loss fucntion for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the checkpoints files location and load the weights if they exist for a specific bit size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/cycle_gan_{0}\".format(STEN_X)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the checkpoints files location and load the weights if they exist for the Bit Size Training Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/cycle_gan_bit_size\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager_bit = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ckpt_manager_bit.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager_bit.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bit Size Training Technique\n",
    "\n",
    "After the end of every epoch, the bit size used is randomly choosen. This allows for each epoch to be trained using a new bit size. At the end of training, the checkpoint is saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "    for x in trange(STEPS_PER_EPOCH, desc=\"Steps per Epoch\"):\n",
    "        STEN_X = np.random.randint(0,9)\n",
    "        try:\n",
    "            set_1 = np.random.randint(1,11)\n",
    "            set_2 = np.random.randint(1,6)\n",
    "            name = str(set_1) + '_' + str(set_2)\n",
    "            encoded = np.load(os.getcwd() + \"/encodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            decoded = np.load(os.getcwd() + \"/decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            train_step(np.asarray([encoded/255.0], dtype='float32'), np.asarray([decoded/255.0], dtype='float32'))\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "ckpt_manager_bit.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the CycleGAN model for a specific bit size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "    for x in trange(STEPS_PER_EPOCH, desc=\"Steps per Epoch\"):\n",
    "        try:\n",
    "            set_1 = np.random.randint(1,11)\n",
    "            set_2 = np.random.randint(1,6)\n",
    "            name = str(set_1) + '_' + str(set_2)\n",
    "            encoded = np.load(os.getcwd() + \"/encodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            decoded = np.load(os.getcwd() + \"/decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            train_step(np.asarray([encoded/255.0], dtype='float32'), np.asarray([decoded/255.0], dtype='float32'))\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model and generate the image for the CycleGAN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_imgs = np.empty((0, 256, 256, 3))\n",
    "hidden_imgs = np.empty((0, 256, 256, 3))\n",
    "encoded_imgs = np.empty((0, 256, 256, 3))\n",
    "decoded_imgs = np.empty((0, 256, 256, 3))\n",
    "for x in range(5):\n",
    "    set_1 = x+11\n",
    "    set_2 = x+6\n",
    "    name = str(set_1) + '_' + str(set_2)\n",
    "    cover = mpimg.imread(os.getcwd() + \"/data/set1/{0}.jpg\".format(set_1)) / 255.0\n",
    "    hidden = mpimg.imread(os.getcwd() + \"/data/set2/{0}.jpg\".format(set_2)) / 255.0\n",
    "    encoded = np.load(os.getcwd() + \"/encodedArray/bit_{0}/{1}.npy\".format(STEN_X, name)) / 255.0\n",
    "    decoded = np.load(os.getcwd() + \"/decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name)) / 255.0\n",
    "    cover_imgs = np.row_stack((cover_imgs, np.asarray([cover])))\n",
    "    hidden_imgs = np.row_stack((hidden_imgs, np.asarray([hidden])))\n",
    "    encoded_imgs = np.row_stack((encoded_imgs, np.asarray([encoded])))\n",
    "    decoded_imgs = np.row_stack((decoded_imgs, np.asarray([decoded])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images for Bit Size Training Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(generator_g, generator_f, cover_imgs, hidden_imgs, encoded_imgs, decoded_imgs, \"bit_size_training.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images for specific bit size training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(generator_g, generator_f, cover_imgs, hidden_imgs, encoded_imgs, decoded_imgs, \"cycle_gan_{0}.png\".format(STEN_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder: The following code shows how to run the Autoencoder code from scratch or with the use of saved weights\n",
    "\n",
    "The following section contains the results of our Autoencoder to compare to our CycleGAN.\n",
    "\n",
    "These are the main hyper-parameters that can be altered for this model. The STEN_X specifies to the model which bit size to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 50\n",
    "IMG_ROWS, IMG_COLS = 256, 256\n",
    "SAVE_RATE = 100\n",
    "STEN_X = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Generator for Keras to load the data but not hold all of it in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Sequence) :\n",
    "    def __init__(self, image_filenames, batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        X = []\n",
    "        Y = []\n",
    "        for file in batch_x:\n",
    "            name = file[21:-4]\n",
    "            X.append(np.load(file) / 255.0)\n",
    "            Y.append(np.load(\"./decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name)) / 255.0)\n",
    "        X = np.asarray(X)\n",
    "        Y = np.asarray(Y)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generate_images function prints and saves the cover image, hidden image, encoded image, decoded image, and the predicted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, cover_imgs, hidden_imgs, encoded_imgs, decoded_imgs, save_name):\n",
    "    fig, axs = plt.subplots(len(cover_imgs), 5, figsize=(15,15))\n",
    "    cols = [\"Cover\", \"Hidden\", \"Encoded\", \"Decoded\", \"Predicted\"]\n",
    "    for x in range(len(cover_imgs)):\n",
    "        predicted = model.predict(np.asarray([encoded]))\n",
    "        display_list = [cover_imgs[x], hidden_imgs[x], encoded_imgs[x], decoded_imgs[x], predicted[0]]\n",
    "        [axs[x, y].imshow(display_list[y] * 0.5 + 0.5) for y in range(5)]\n",
    "    [ax.set_title(col,fontsize=40) for ax, col in zip(axs[0], cols)]\n",
    "    [axi.set_axis_off() for axi in axs.ravel()]\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (IMG_ROWS, IMG_COLS, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential()\n",
    "\n",
    "autoencoder.add(Conv2D(64, (8, 8), padding='same', input_shape=shape))\n",
    "autoencoder.add(Activation('relu'))\n",
    "autoencoder.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "autoencoder.add(Conv2D(32,(5, 5), padding='same'))\n",
    "autoencoder.add(Activation('relu'))\n",
    "autoencoder.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "autoencoder.add(Conv2D(32,(5, 5), padding='same'))\n",
    "autoencoder.add(Activation('relu'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "\n",
    "autoencoder.add(Conv2D(64,(8, 8), padding='same'))\n",
    "autoencoder.add(Activation('relu'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "\n",
    "autoencoder.add(Conv2D(3,(3, 3), padding='same'))\n",
    "autoencoder.add(Activation('sigmoid'))\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/autoencoder_{0}\".format(STEN_X)\n",
    "ckpt = tf.train.Checkpoint(autoencoder=autoencoder)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Autoencoder model with a Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"./encodedArray/bit_{0}/*\".format(STEN_X))\n",
    "train = files\n",
    "train_gen = Generator(train, BATCH_SIZE)\n",
    "autoencoder.fit_generator(generator=train_gen,\n",
    "                    epochs = EPOCHS,\n",
    "                    verbose = 1,\n",
    "                    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model and generate the image for the CycleGAN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_imgs = np.empty((0, 256, 256, 3))\n",
    "hidden_imgs = np.empty((0, 256, 256, 3))\n",
    "encoded_imgs = np.empty((0, 256, 256, 3))\n",
    "decoded_imgs = np.empty((0, 256, 256, 3))\n",
    "for x in range(5):\n",
    "    set_1 = x+11\n",
    "    set_2 = x+6\n",
    "    name = str(set_1) + '_' + str(set_2)\n",
    "    cover = mpimg.imread(os.getcwd() + \"/data/set1/{0}.jpg\".format(set_1)) / 255.0\n",
    "    hidden = mpimg.imread(os.getcwd() + \"/data/set2/{0}.jpg\".format(set_2)) / 255.0\n",
    "    encoded = np.load(os.getcwd() + \"/encodedArray/bit_{0}/{1}.npy\".format(STEN_X, name)) / 255.0\n",
    "    decoded = np.load(os.getcwd() + \"/decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name)) / 255.0\n",
    "    cover_imgs = np.row_stack((cover_imgs, np.asarray([cover])))\n",
    "    hidden_imgs = np.row_stack((hidden_imgs, np.asarray([hidden])))\n",
    "    encoded_imgs = np.row_stack((encoded_imgs, np.asarray([encoded])))\n",
    "    decoded_imgs = np.row_stack((decoded_imgs, np.asarray([decoded])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images for Autoencoder for specific bit size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(autoencoder, cover_imgs, hidden_imgs, encoded_imgs, decoded_imgs, \"autoencoder_{}.png\".format(STEN_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization with CycleGAN: The following code shows how to run Bayesian Optimzation and save the results\n",
    "\n",
    "These are the main hyper-parameters that can be altered for this model. The STEN_X specifies to the model which bit size to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEN_X = 7\n",
    "MAX0 = 11\n",
    "MAX1 = 6\n",
    "EPOCHS_RANGE = (200, 500)\n",
    "LAMBDA_RANGE = (8, 12)\n",
    "STEPS_PER_EPOCH_RANGE = (10, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator_loss calculates the loss for the discriminator model in the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "    real_loss = loss_obj(tf.ones_like(real), real)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "    return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator_loss calculates the loss for the generator model in the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "    return loss_obj(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calc_cycle_loss calculates the loss for a single cycle with an encoded image through the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cycle_loss(LAMBDA, real_image, cycled_image):\n",
    "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return int(LAMBDA) * loss1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identity_loss calculates the identity loss for an image and the same image passed into the corresponding generator which should not alter the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(LAMBDA, real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return int(LAMBDA) * 0.5 * loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model runs through the train_step for every encoded and decoded image passed into it. This is the function that changes the weights of our model as it progresses. This step has been modified to run with Bayesian Optmization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(LAMBDA,real_x, real_y): \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "\n",
    "        cycled_x = generator_f(fake_y, training=True) \n",
    "\n",
    "        fake_x = generator_f(real_y, training=True) \n",
    "        cycled_y = generator_g(fake_x, training=True) \n",
    "\n",
    "        same_x = generator_f(real_x, training=True) \n",
    "        same_y = generator_g(real_y, training=True) \n",
    "\n",
    "        disc_real_x = discriminator_x(real_x, training=True) \n",
    "        disc_real_y = discriminator_y(real_y, training=True)\n",
    "\n",
    "        disc_fake_x = discriminator_x(fake_x, training=True) \n",
    "        disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "        gen_g_loss = generator_loss(disc_fake_y)  \n",
    "        gen_f_loss = generator_loss(disc_fake_x) \n",
    "\n",
    "        total_cycle_loss = calc_cycle_loss(LAMBDA,real_x, cycled_x) + calc_cycle_loss(LAMBDA,real_y, cycled_y)\n",
    "\n",
    "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(LAMBDA, real_y, same_y)\n",
    "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(LAMBDA, real_x, same_x)\n",
    "\n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x) \n",
    "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y) \n",
    "\n",
    "    generator_g_gradients = tape.gradient(total_gen_g_loss,generator_g.trainable_variables)\n",
    "    generator_f_gradients = tape.gradient(total_gen_f_loss, generator_f.trainable_variables)\n",
    "    discriminator_x_gradients = tape.gradient(disc_x_loss,discriminator_x.trainable_variables)\n",
    "    discriminator_y_gradients = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)\n",
    "\n",
    "    generator_g_optimizer.apply_gradients(zip(generator_g_gradients,generator_g.trainable_variables))\n",
    "    generator_f_optimizer.apply_gradients(zip(generator_f_gradients, generator_f.trainable_variables))\n",
    "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,discriminator_x.trainable_variables))\n",
    "    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function for Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    return -err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the generator models, discriminator models, and loss fucntion for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the specified Black-box function that Bayesian Optimization will maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Black_Box(EPOCHS,LAMBDA,steps_per_epochs):\n",
    "    for epoch in trange(int(EPOCHS),desc='epochs'):\n",
    "        for _ in trange(int(steps_per_epochs), desc='steps_per_epochs'):\n",
    "            i = np.random.randint(1,MAX0)\n",
    "            j = np.random.randint(1,MAX1)\n",
    "            name = str(i) + '_' + str(j)\n",
    "            image_x = np.load(os.getcwd() + \"/encodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            image_y = np.load(os.getcwd() + \"/decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            train_step(LAMBDA,np.asarray([image_x/255.0], dtype='float32'), np.asarray([image_y/255.0], dtype='float32'))\n",
    "    sum = 0.0\n",
    "    for i in trange(1,MAX0):\n",
    "        for j in trange(1,MAX1):\n",
    "            name = str(i) + '_' + str(j)\n",
    "            image_x = np.load(os.getcwd() + \"/encodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            image_y = np.load(os.getcwd() + \"/decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            sum += mse(generator_g.predict(np.asarray([image_x/255.0], dtype='float32')), np.asarray([image_y/255.0], dtype='float32'))\n",
    "    avg = sum / ((MAX0-1)*(MAX1-1))\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounds for the Bayesian Optimization to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = {\n",
    "    'EPOCHS': EPOCHS_RANGE,\n",
    "    'LAMBDA': LAMBDA_RANGE,\n",
    "    'steps_per_epochs': STEPS_PER_EPOCH_RANGE \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f = Black_Box,\n",
    "    pbounds = bounds,\n",
    "    random_state = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results to a log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = JSONLogger(path=\"./logs_{0}.json\".format(STEN_X))\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.maximize(init_points=2,n_iter=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
