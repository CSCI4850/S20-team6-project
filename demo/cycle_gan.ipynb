{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries necessary for the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "from sten import Sten\n",
    "from matplotlib.image import imread\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure session and GPU options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the progress of the CycleGAN during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(max_epoch, epoch, progress, episode):\n",
    "    bar_length = 50\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Episode {0}, Progress: [{1}] {2:.1f}%, Epoch {3}/{4}\".format(episode, \"=\" * block + \".\" * (bar_length - block), progress * 100, epoch, max_epoch)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prints and saves the cover image, hidden image, encoded image, decoded image, the image generated by Generator G (decoded image), and the image generated by generator F (encoded image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator_g, generator_f, cover_imgs, hidden_imgs, encoded_imgs, decoded_imgs, save_name):\n",
    "    fig, axs = plt.subplots(len(cover_imgs), 6, figsize=(25,25))\n",
    "    cols = [\"Cover\", \"Hidden\", \"Encoded\", \"Decoded\", \"Generator G\", \"Generator F\"]\n",
    "    for x in range(len(cover_imgs)):\n",
    "        predicted_g = generator_g.predict(np.asarray([encoded_imgs[x]]))\n",
    "        predicted_f = generator_f.predict(np.asarray([predicted_g[0]]))\n",
    "        display_list = [cover_imgs[x], hidden_imgs[x], encoded_imgs[x], decoded_imgs[x], predicted_g[0], predicted_f[0]]\n",
    "        [axs[x, y].imshow(display_list[y] * 0.5 + 0.5) for y in range(6)]\n",
    "    [ax.set_title(col,fontsize=40) for ax, col in zip(axs[0], cols)]\n",
    "    [axi.set_axis_off() for axi in axs.ravel()]\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates the loss for the discriminator model in the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(a, generated):\n",
    "    a_loss = loss_obj(tf.ones_like(a), a)\n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "    total_disc_loss = a_loss + generated_loss\n",
    "    return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates the loss for the generator model in the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "    return loss_obj(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates the loss for a single cycle with an encoded image through the CycleGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cycle_loss(a_image, cycled_image):\n",
    "    loss1 = tf.reduce_mean(tf.abs(a_image - cycled_image))\n",
    "    return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates the identity loss for an image and the same image passed into the corresponding generator which should not alter the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(a_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(a_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function that is called for every step of each epoch with the encoded and decoded images passed into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(a_x, a_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "            \n",
    "        fake_y = generator_g(a_x, training=True)\n",
    "        cycled_x = generator_f(fake_y, training=True)\n",
    "\n",
    "        fake_x = generator_f(a_y, training=True)\n",
    "        cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "        same_x = generator_f(a_x, training=True)\n",
    "        same_y = generator_g(a_y, training=True)\n",
    "\n",
    "        disc_a_x = discriminator_x(a_x, training=True)\n",
    "        disc_a_y = discriminator_y(a_y, training=True)\n",
    "\n",
    "        disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "        disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "        gen_g_loss = generator_loss(disc_fake_y)\n",
    "        gen_f_loss = generator_loss(disc_fake_x)\n",
    "\n",
    "        total_cycle_loss = calc_cycle_loss(a_x, cycled_x) + calc_cycle_loss(a_y, cycled_y)\n",
    "\n",
    "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(a_y, same_y)\n",
    "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(a_x, same_x)\n",
    "\n",
    "        disc_x_loss = discriminator_loss(disc_a_x, disc_fake_x)\n",
    "        disc_y_loss = discriminator_loss(disc_a_y, disc_fake_y)\n",
    "  \n",
    "    generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
    "                                        generator_g.trainable_variables)\n",
    "    generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
    "                                        generator_f.trainable_variables)\n",
    "\n",
    "    discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                            discriminator_x.trainable_variables)\n",
    "    discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
    "                                            discriminator_y.trainable_variables)\n",
    "\n",
    "    generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            generator_g.trainable_variables))\n",
    "\n",
    "    generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            generator_f.trainable_variables))\n",
    "\n",
    "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                discriminator_x.trainable_variables))\n",
    "\n",
    "    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH = 50\n",
    "LAMBDA = 10\n",
    "SAVE_RATE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the generator models, discriminator models, and loss fucntion for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saves the current state of the CycleGAN along with its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"checkpoints/train_sten\"\n",
    "\n",
    "# ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "#                            generator_f=generator_f,\n",
    "#                            discriminator_x=discriminator_x,\n",
    "#                            discriminator_y=discriminator_y,\n",
    "#                            generator_g_optimizer=generator_g_optimizer,\n",
    "#                            generator_f_optimizer=generator_f_optimizer,\n",
    "#                            discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "#                            discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if ckpt_manager.latest_checkpoint:\n",
    "#     ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "#     print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the CycleGAN, prepare the input and output images to be printed and saved, and save the current checkpoint after training has completed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "    for x in trange(STEPS_PER_EPOCH, desc=\"Steps per Epoch\"):\n",
    "        STEN_X = np.random.randint(0,9)\n",
    "        try:\n",
    "            set_1 = np.random.randint(1,11)\n",
    "            set_2 = np.random.randint(1,6)\n",
    "            name = str(set_1) + '_' + str(set_2)\n",
    "            encoded = np.load(os.getcwd() + \"/encodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            decoded = np.load(os.getcwd() + \"/decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name))\n",
    "            train_step(np.asarray([encoded/255.0], dtype='float32'), np.asarray([decoded/255.0], dtype='float32'))\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "\n",
    "cover_imgs = np.empty((0, 256, 256, 3))\n",
    "hidden_imgs = np.empty((0, 256, 256, 3))\n",
    "encoded_imgs = np.empty((0, 256, 256, 3))\n",
    "decoded_imgs = np.empty((0, 256, 256, 3))\n",
    "for x in range(5):\n",
    "    set_1 = x+1\n",
    "    set_2 = x+1\n",
    "    name = str(set_1) + '_' + str(set_2)\n",
    "    cover = mpimg.imread(os.getcwd() + \"/data/set1/{0}.jpg\".format(set_1)) / 255.0\n",
    "    hidden = mpimg.imread(os.getcwd() + \"/data/set2/{0}.jpg\".format(set_2)) / 255.0\n",
    "    encoded = np.load(os.getcwd() + \"/encodedArray/bit_{0}/{1}.npy\".format(STEN_X, name)) / 255.0\n",
    "    decoded = np.load(os.getcwd() + \"/decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name)) / 255.0\n",
    "    cover_imgs = np.row_stack((cover_imgs, np.asarray([cover])))\n",
    "    hidden_imgs = np.row_stack((hidden_imgs, np.asarray([hidden])))\n",
    "    encoded_imgs = np.row_stack((encoded_imgs, np.asarray([encoded])))\n",
    "    decoded_imgs = np.row_stack((decoded_imgs, np.asarray([decoded])))\n",
    "    \n",
    "# generate_images(generator_g, generator_f, cover_imgs, hidden_imgs, encoded_imgs, decoded_imgs, \"bayes_good.png\")\n",
    "\n",
    "checkpoint_path = \"checkpoints/cycle_gan_bit_size\"\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "# if ckpt_manager.latest_checkpoint:\n",
    "#     ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "#     print ('Latest checkpoint restored!!')\n",
    "\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the current checkpoint after the CycleGAN training has completed, and prepare the input and output images to be printed and saved. Then, call generate_images() with the corresponding image parameters to print and save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEN_X = 8\n",
    "\n",
    "# checkpoint_path = \"checkpoints/cycle_gan_{0}\".format(STEN_X)\n",
    "# ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "#                            generator_f=generator_f,\n",
    "#                            discriminator_x=discriminator_x,\n",
    "#                            discriminator_y=discriminator_y,\n",
    "#                            generator_g_optimizer=generator_g_optimizer,\n",
    "#                            generator_f_optimizer=generator_f_optimizer,\n",
    "#                            discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "#                            discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "# if ckpt_manager.latest_checkpoint:\n",
    "#     ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "#     print ('Latest checkpoint restored!!')\n",
    "\n",
    "for x in range(9):\n",
    "    STEN_X = x\n",
    "    cover_imgs = np.empty((0, 256, 256, 3))\n",
    "    hidden_imgs = np.empty((0, 256, 256, 3))\n",
    "    encoded_imgs = np.empty((0, 256, 256, 3))\n",
    "    decoded_imgs = np.empty((0, 256, 256, 3))\n",
    "    for x in range(5):\n",
    "        set_1 = x+1\n",
    "        set_2 = x+1\n",
    "        name = str(set_1) + '_' + str(set_2)\n",
    "        cover = mpimg.imread(os.getcwd() + \"/data/set1/{0}.jpg\".format(set_1)) / 255.0\n",
    "        hidden = mpimg.imread(os.getcwd() + \"/data/set2/{0}.jpg\".format(set_2)) / 255.0\n",
    "        encoded = np.load(os.getcwd() + \"/encodedArray/bit_{0}/{1}.npy\".format(STEN_X, name)) / 255.0\n",
    "        decoded = np.load(os.getcwd() + \"/decodedArray/bit_{0}/{1}.npy\".format(STEN_X, name)) / 255.0\n",
    "        cover_imgs = np.row_stack((cover_imgs, np.asarray([cover])))\n",
    "        hidden_imgs = np.row_stack((hidden_imgs, np.asarray([hidden])))\n",
    "        encoded_imgs = np.row_stack((encoded_imgs, np.asarray([encoded])))\n",
    "        decoded_imgs = np.row_stack((decoded_imgs, np.asarray([decoded])))\n",
    "    generate_images(generator_g, generator_f, cover_imgs, hidden_imgs, encoded_imgs, decoded_imgs, \"bit_size_training_{}.png\".format(STEN_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
