@article{zhu_unpaired_2018,
	title = {Unpaired {Image}-to-{Image} {Translation} using {Cycle}-{Consistent} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1703.10593},
	abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain \$X\$ to a target domain \$Y\$ in the absence of paired examples. Our goal is to learn a mapping \$G: X {\textbackslash}rightarrow Y\$ such that the distribution of images from \$G(X)\$ is indistinguishable from the distribution \$Y\$ using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping \$F: Y {\textbackslash}rightarrow X\$ and introduce a cycle consistency loss to push \$F(G(X)) {\textbackslash}approx X\$ (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
	urldate = {2020-04-28},
	journal = {arXiv:1703.10593 [cs]},
	author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	month = nov,
	year = {2018},
	note = {arXiv: 1703.10593},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{mirza_conditional_2014,
	title = {Conditional {Generative} {Adversarial} {Nets}},
	url = {http://arxiv.org/abs/1411.1784},
	abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
	urldate = {2020-04-28},
	journal = {arXiv:1411.1784 [cs, stat]},
	author = {Mirza, Mehdi and Osindero, Simon},
	month = nov,
	year = {2014},
	note = {arXiv: 1411.1784},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning}
}

@article{pathak_context_2016,
	title = {Context {Encoders}: {Feature} {Learning} by {Inpainting}},
	shorttitle = {Context {Encoders}},
	url = {http://arxiv.org/abs/1604.07379},
	abstract = {We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders -- a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.},
	urldate = {2020-04-28},
	journal = {arXiv:1604.07379 [cs]},
	author = {Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A.},
	month = nov,
	year = {2016},
	note = {arXiv: 1604.07379},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Graphics, Computer Science - Machine Learning}
}

@article{johnson_exploring_1998,
	title = {Exploring steganography: {Seeing} the unseen},
	volume = {31},
	issn = {1558-0814},
	shorttitle = {Exploring steganography},
	doi = {10.1109/MC.1998.4655281},
	abstract = {Steganography is the art of hiding information in ways that prevent the detection of hidden messages. It includes a vast array of secret communications methods that conceal the message's very existence. These methods include invisible inks, microdots, character arrangement, digital signatures, covert channels, and spread spectrum communications. Steganography and cryptography are cousins in the spycraft family: cryptography scrambles a message so it cannot be understood while steganography hides the message so it cannot be seen. In this article the authors discuss image files and how to hide information in them, and discuss results obtained from evaluating available steganographic software. They argue that steganography by itself does not ensure secrecy, but neither does simple encryption. If these methods are combined, however, stronger encryption methods result. If an encrypted message is intercepted, the interceptor knows the text is an encrypted message. But with steganography, the interceptor may not know that a hidden message even exists. For a brief look at how steganography evolved, there is included a sidebar titled "Steganography: Some History."},
	number = {2},
	journal = {Computer},
	author = {Johnson, Neil F. and Jajodia, Sushil},
	month = feb,
	year = {1998},
	keywords = {Steganography, Image coding, Cryptography, Digital images, Graphics, Transform coding, Ink},
	pages = {26--34}
}

@article{singh2015steganography,
  title={Steganography in Images Using LSB Technique},
  author={Singh, Arun Kumar and Singh, Juhi and Singh, Harsh Vikram},
  journal={International Journal of Latest Trends in Engineering and Technology (IJLTET)},
  volume={5},
  number={1},
  pages={426--430},
  year={2015}
}

@article{chen_deep_2017,
	title = {Deep {Features} {Learning} for {Medical} {Image} {Analysis} with {Convolutional} {Autoencoder} {Neural} {Network}},
	issn = {2332-7790},
	doi = {10.1109/TBDATA.2017.2717439},
	abstract = {At present, computed tomography (CT) are widely used to assist diagnosis. Especially, computer aided diagnosis (CAD) based on artificial intelligence (AI) is an extremely important research field in intelligent healthcare. However, it is a great challenge to establish an adequate labeled dataset for CT analysis assistance, due to the privacy and security issues. Therefore, this paper proposes a convolutional autoencoder deep learning framework to support unsupervised image features learning for lung nodule through unlabeled data, which only needs a small amount of labeled data for efficient feature learning. Through comprehensive experiments, it evaluates that the proposed scheme is superior to other approaches, which effectively solves the intrinsic labor-intensive problem during of artificial image labeling. Moreover, it verifies that the proposed convolutional autoencoder approach can be extended for similarity measurement of lung nodules images. Especially, the features extracted through unsupervised learning are also applicable in other related scenarios.},
	journal = {IEEE Transactions on Big Data},
	author = {Chen, Min and Shi, Xiaobo and Zhang, Yin and Wu, Di and Guizani, Mohsen},
	year = {2017},
	keywords = {Feature extraction, Computed tomography, Biomedical imaging, Convolutional codes, Lungs, Training, Image analysis, Convolutional autoencoder neural network, Lung nodule, Feature learning, Hand-craft feature, Unsupervised learning},
	pages = {1--1}
}

@Misc{bayes_opt,
    author = {Fernando Nogueira},
    title = {{Bayesian Optimization}: Open source constrained global optimization tool for {Python}},
    year = {2014--},
    url = " https://github.com/fmfn/BayesianOptimization"
}

@article{snoek_practical_2012,
	title = {Practical {Bayesian} {Optimization} of {Machine} {Learning} {Algorithms}},
	url = {http://arxiv.org/abs/1206.2944},
	abstract = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a "black art" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
	urldate = {2020-04-28},
	journal = {arXiv:1206.2944 [cs, stat]},
	author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
	month = aug,
	year = {2012},
	note = {arXiv: 1206.2944},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning}
}

@article{brochu_tutorial_2010,
	title = {A {Tutorial} on {Bayesian} {Optimization} of {Expensive} {Cost} {Functions}, with {Application} to {Active} {User} {Modeling} and {Hierarchical} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1012.2599},
	abstract = {We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.},
	urldate = {2020-04-28},
	journal = {arXiv:1012.2599 [cs]},
	author = {Brochu, Eric and Cora, Vlad M. and de Freitas, Nando},
	month = dec,
	year = {2010},
	note = {arXiv: 1012.2599},
	keywords = {Computer Science - Machine Learning, G.1.6, G.3, I.2.6}
}

@book{rasmussen_gaussian_2006,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {Gaussian processes for machine learning},
	isbn = {9780262182539},
	publisher = {MIT Press},
	author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
	year = {2006},
	note = {OCLC: ocm61285753},
	keywords = {Gaussian processes, Data processing, Machine learning, Mathematical models}
}

@inproceedings{seethalakshmi_security_2016,
	title = {Security enhancement in image steganography using neural networks and visual cryptography},
	doi = {10.1109/CSITSS.2016.7779393},
	abstract = {Data Security has been an essential area of concern as the communication medium is widely used over internet. Image steganography indicates sending the secret data in the cover image while hiding the very existence of it self. Before embedding the secret data in the cover image, it is encrypted in order to obtain better level of security. Steganalysis is concerned with field of defeating steganographic techniques. Hence continuous research has been under taken in order to enhance data security. Cryptography involves a process called encryption and is not concerned with hiding the secret data in the cover image. Visual cryptography is a renowned technique to protect data which is image based. During encryption, the image is split into `n' number of shares. During decryption, these shares are stacked together to get original image. Hence specific decryption algorithm is not necessary and just human visual system would suffice. In order to enhance security mechanism, visual cryptography and image steganography are used together. Neural networks are concerned with identifying the best locations in host image in order to embed the secret data thus improving the image quality.},
	booktitle = {2016 {International} {Conference} on {Computation} {System} and {Information} {Technology} for {Sustainable} {Solutions} ({CSITSS})},
	author = {Seethalakshmi, K.S. and {Usha B A} and {Sangeetha K N}},
	month = oct,
	year = {2016},
	keywords = {data protection, image processing, neural nets, steganography, image steganography, neural networks, visual cryptography, data security enhancement, communication medium, Internet, secret data hiding, human visual system, image quality, encryption, data protection, decryption, Encryption, Databases, Artificial neural networks, Heuristic algorithms, Algorithm design and analysis, Wavelet analysis, Integer Wavelet Transformation (IWT), Cryptography steganography image steganography steganography neural networks (NN), radial basis function(RBF)},
	pages = {396--403}
}

@article{welander_generative_2018,
	title = {Generative {Adversarial} {Networks} for {Image}-to-{Image} {Translation} on {Multi}-{Contrast} {MR} {Images} - {A} {Comparison} of {CycleGAN} and {UNIT}},
	url = {http://arxiv.org/abs/1806.07777},
	abstract = {In medical imaging, a general problem is that it is costly and time consuming to collect high quality data from healthy and diseased subjects. Generative adversarial networks (GANs) is a deep learning method that has been developed for synthesizing data. GANs can thereby be used to generate more realistic training data, to improve classification performance of machine learning algorithms. Another application of GANs is image-to-image translations, e.g. generating magnetic resonance (MR) images from computed tomography (CT) images, which can be used to obtain multimodal datasets from a single modality. Here, we evaluate two unsupervised GAN models (CycleGAN and UNIT) for image-to-image translation of T1- and T2-weighted MR images, by comparing generated synthetic MR images to ground truth images. We also evaluate two supervised models; a modification of CycleGAN and a pure generator model. A small perceptual study was also performed to evaluate how visually realistic the synthesized images are. It is shown that the implemented GAN models can synthesize visually realistic MR images (incorrectly labeled as real by a human). It is also shown that models producing more visually realistic synthetic images not necessarily have better quantitative error measurements, when compared to ground truth data. Code is available at https://github.com/simontomaskarlsson/GAN-MRI},
	urldate = {2020-04-28},
	journal = {arXiv:1806.07777 [cs]},
	author = {Welander, Per and Karlsson, Simon and Eklund, Anders},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.07777},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{meng_steganography_2019,
	title = {A {Steganography} {Algorithm} {Based} on {CycleGAN} for {Covert} {Communication} in the {Internet} of {Things}},
	volume = {7},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8731888/},
	doi = {10.1109/ACCESS.2019.2920956},
	urldate = {2020-04-28},
	journal = {IEEE Access},
	author = {Meng, Ruohan and Cui, Qi and Zhou, Zhili and Fu, Zhangjie and Sun, Xingming},
	year = {2019},
	pages = {90574--90584}
}

@article{siper2005rise,
  title={The rise of steganography},
  author={Siper, Alan and Farley, Roger and Lombardo, Craig},
  journal={Proceedings of student/faculty research day, CSIS, Pace University},
  year={2005}
}

@article{goodfellow_generative_2014,
	title = {Generative {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	urldate = {2020-04-28},
	journal = {arXiv:1406.2661 [cs, stat]},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	month = jun,
	year = {2014},
	note = {arXiv: 1406.2661},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning}
}

@article{radford_unsupervised_2016,
	title = {Unsupervised {Representation} {Learning} with {Deep} {Convolutional} {Generative} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1511.06434},
	abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
	urldate = {2020-04-28},
	journal = {arXiv:1511.06434 [cs]},
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	month = jan,
	year = {2016},
	note = {arXiv: 1511.06434},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition}
}

@article{paloniemi_introduction_2020,
	title = {Introduction to {Generative} {Adversarial} {Networks}},
	url = {https://aaltodoc.aalto.fi:443/handle/123456789/42782},
	language = {en},
	urldate = {2020-04-28},
	journal = {Aalto University},
	author = {Paloniemi, Manu},
	month = jan,
	year = {2020}
}

@article{chu_cyclegan_2017,
	title = {{CycleGAN}, a {Master} of {Steganography}},
	url = {http://arxiv.org/abs/1712.02950},
	abstract = {CycleGAN (Zhu et al. 2017) is one recent successful approach to learn a transformation between two image distributions. In a series of experiments, we demonstrate an intriguing property of the model: CycleGAN learns to "hide" information about a source image into the images it generates in a nearly imperceptible, high-frequency signal. This trick ensures that the generator can recover the original sample and thus satisfy the cyclic consistency requirement, while the generated image remains realistic. We connect this phenomenon with adversarial attacks by viewing CycleGAN's training procedure as training a generator of adversarial examples and demonstrate that the cyclic consistency loss causes CycleGAN to be especially vulnerable to adversarial attacks.},
	urldate = {2020-04-28},
	journal = {arXiv:1712.02950 [cs, stat]},
	author = {Chu, Casey and Zhmoginov, Andrey and Sandler, Mark},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.02950},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning}
}

@article{isola_image--image_2018,
	title = {Image-to-{Image} {Translation} with {Conditional} {Adversarial} {Networks}},
	url = {http://arxiv.org/abs/1611.07004},
	abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Indeed, since the release of the pix2pix software associated with this paper, a large number of internet users (many of them artists) have posted their own experiments with our system, further demonstrating its wide applicability and ease of adoption without the need for parameter tweaking. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
	urldate = {2020-04-28},
	journal = {arXiv:1611.07004 [cs]},
	author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
	month = nov,
	year = {2018},
	note = {arXiv: 1611.07004},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{gomez_unsupervised_2018,
	title = {Unsupervised {Cipher} {Cracking} {Using} {Discrete} {GANs}},
	url = {http://arxiv.org/abs/1801.04883},
	abstract = {This work details CipherGAN, an architecture inspired by CycleGAN used for inferring the underlying cipher mapping given banks of unpaired ciphertext and plaintext. We demonstrate that CipherGAN is capable of cracking language data enciphered using shift and Vigenere ciphers to a high degree of fidelity and for vocabularies much larger than previously achieved. We present how CycleGAN can be made compatible with discrete data and train in a stable way. We then prove that the technique used in CipherGAN avoids the common problem of uninformative discrimination associated with GANs applied to discrete data.},
	urldate = {2020-04-28},
	journal = {arXiv:1801.04883 [cs]},
	author = {Gomez, Aidan N. and Huang, Sicong and Zhang, Ivan and Li, Bryan M. and Osama, Muhammad and Kaiser, Lukasz},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.04883},
	keywords = {Computer Science - Machine Learning}
}

@article{ng2011sparse,
  title={Sparse autoencoder},
  author={Ng, Andrew and others},
  journal={CS294A Lecture notes},
  volume={72},
  number={2011},
  pages={1--19},
  year={2011}
}

@article{schmidhuber_deep_2015,
	title = {Deep {Learning} in {Neural} {Networks}: {An} {Overview}},
	volume = {61},
	issn = {08936080},
	shorttitle = {Deep {Learning} in {Neural} {Networks}},
	url = {http://arxiv.org/abs/1404.7828},
	doi = {10.1016/j.neunet.2014.09.003},
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	urldate = {2020-04-28},
	journal = {Neural Networks},
	author = {Schmidhuber, Juergen},
	month = jan,
	year = {2015},
	note = {arXiv: 1404.7828},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Machine Learning},
	pages = {85--117}
}

@inproceedings{guo_deep_2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Deep {Clustering} with {Convolutional} {Autoencoders}},
	isbn = {9783319700960},
	doi = {10.1007/978-3-319-70096-0_39},
	abstract = {Deep clustering utilizes deep neural networks to learn feature representation that is suitable for clustering tasks. Though demonstrating promising performance in various applications, we observe that existing deep clustering algorithms either do not well take advantage of convolutional neural networks or do not considerably preserve the local structure of data generating distribution in the learned feature space. To address this issue, we propose a deep convolutional embedded clustering algorithm in this paper. Specifically, we develop a convolutional autoencoders structure to learn embedded features in an end-to-end way. Then, a clustering oriented loss is directly built on embedded features to jointly perform feature refinement and cluster assignment. To avoid feature space being distorted by the clustering loss, we keep the decoder remained which can preserve local structure of data in feature space. In sum, we simultaneously minimize the reconstruction loss of convolutional autoencoders and the clustering loss. The resultant optimization problem can be effectively solved by mini-batch stochastic gradient descent and back-propagation. Experiments on benchmark datasets empirically validate the power of convolutional autoencoders for feature learning and the effectiveness of local structure preservation.},
	language = {en},
	booktitle = {Neural {Information} {Processing}},
	publisher = {Springer International Publishing},
	author = {Guo, Xifeng and Liu, Xinwang and Zhu, En and Yin, Jianping},
	editor = {Liu, Derong and Xie, Shengli and Li, Yuanqing and Zhao, Dongbin and El-Alfy, El-Sayed M.},
	year = {2017},
	keywords = {Deep clustering ,  Convolutional autoencoders ,  Convolutional neural networks ,  Unsupervised learning },
	pages = {373--382}
}

@book{katz_introduction_2015,
	address = {Boca Raton},
	edition = {Second edition},
	series = {Chapman \& hall/crc cryptography and network security series},
	title = {Introduction to modern cryptography},
	isbn = {9781466570269},
	abstract = {"Cryptography is ubiquitous and plays a key role in ensuring data secrecy and integrity as well as in securing computer systems more broadly. Introduction to Modern Cryptography provides a rigorous yet accessible treatment of this fascinating subject. The authors introduce the core principles of modern cryptography, with an emphasis on formal definitions, clear assumptions, and rigorous proofs of security. The book begins by focusing on private-key cryptography, including an extensive treatment of private-key encryption, message authentication codes, and hash functions. The authors also present design principles for widely used stream ciphers and block ciphers including RC4, DES, and AES, plus provide provable constructions of stream ciphers and block ciphers from lower-level primitives. The second half of the book covers public-key cryptography, beginning with a self-contained introduction to the number theory needed to understand the RSA, Diffie-Hellman, and El Gamal cryptosystems (and others), followed by a thorough treatment of several standardized public-key encryption and digital signature schemes. Integrating a more practical perspective without sacrificing rigor, this widely anticipated Second Edition offers improved treatment of:Stream ciphers and block ciphers, including modes of operation and design principlesAuthenticated encryption and secure communication sessionsHash functions, including hash-function applications and design principles Attacks on poorly implemented cryptography, including attacks on chained-CBC encryption, padding-oracle attacks, and timing attacksThe random-oracle model and its application to several standardized, widely used public-key encryption and signature schemesElliptic-curve cryptography and associated standards such as DSA/ECDSA and DHIES/ECIESContaining updated exercises and worked examples, Introduction to Modern Cryptography, Second Edition can serve as a textbook for undergraduate- or graduate-level courses in cryptography, a valuable reference for researchers and practitioners, or a general introduction suitable for self-study. "--},
	publisher = {CRC Press/Taylor \& Francis},
	author = {Katz, Jonathan and Lindell, Yehuda},
	year = {2015},
	keywords = {Computer security, Cryptography, COMPUTERS / Operating Systems / General, COMPUTERS / Security / Cryptography, MATHEMATICS / Combinatorics}
}

@article{mockus_bayes_1974,
	title = {{THE} {BAYES} {METHODS} {FOR} {SEEKING} {THE} {EXTREMAL} {POINT}},
	volume = {3},
	issn = {0368-492X},
	url = {https://www.emerald.com/insight/content/doi/10.1108/eb005359/full/html},
	doi = {10.1108/eb005359},
	language = {en},
	number = {2},
	urldate = {2020-04-28},
	journal = {Kybernetes},
	author = {Mockus, J.},
	month = feb,
	year = {1974},
	pages = {103--108}
}

@article{mockus_bayes_1975,
	title = {On the {Bayes} {Methods} for {Seeking} the {Extremal} {Point}},
	volume = {8},
	issn = {14746670},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1474667017677693},
	doi = {10.1016/S1474-6670(17)67769-3},
	language = {en},
	number = {1},
	urldate = {2020-04-28},
	journal = {IFAC Proceedings Volumes},
	author = {Mockus, J.},
	month = aug,
	year = {1975},
	pages = {428--431}
}